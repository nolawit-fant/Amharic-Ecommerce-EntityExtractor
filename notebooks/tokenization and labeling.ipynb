{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "os.getcwd()\n",
    "rpath = os.path.abspath('../')\n",
    "if rpath not in sys.path:\n",
    "    sys.path.insert(0,rpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SINA KIDS/ሲና ኪድስⓇ</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>14841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-26 12:24:51+00:00</td>\n",
       "      <td>photos\\@sinayelj_14841.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINA KIDS/ሲና ኪድስⓇ</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>14840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-26 12:24:51+00:00</td>\n",
       "      <td>photos\\@sinayelj_14840.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SINA KIDS/ሲና ኪድስⓇ</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>14839</td>\n",
       "      <td>ለኮንዶሚኒየም ለጠባብ ቤቶች ገላግሌ የሆነ ከንፁህ የሲልከን ጥሬ እቃ የተ...</td>\n",
       "      <td>2024-09-26 12:24:51+00:00</td>\n",
       "      <td>photos\\@sinayelj_14839.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SINA KIDS/ሲና ኪድስⓇ</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>14838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-26 12:24:12+00:00</td>\n",
       "      <td>photos\\@sinayelj_14838.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SINA KIDS/ሲና ኪድስⓇ</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>14837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-26 12:24:12+00:00</td>\n",
       "      <td>photos\\@sinayelj_14837.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>SINA KIDS/ሲና ኪድስⓇ</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-16 18:12:10+00:00</td>\n",
       "      <td>photos\\@sinayelj_599.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>SINA KIDS/ሲና ኪድስⓇ</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>598</td>\n",
       "      <td>Baby potty\\n0905707448\\n0945097042</td>\n",
       "      <td>2021-04-16 18:12:10+00:00</td>\n",
       "      <td>photos\\@sinayelj_598.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620</th>\n",
       "      <td>SINA KIDS/ሲና ኪድስⓇ</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-26 18:30:52+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4621</th>\n",
       "      <td>SINA KIDS/ሲና ኪድስⓇ</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>182</td>\n",
       "      <td>ውድ የሲና ኪድስ ደምበኞች በድጋሚ ገብቷል \\nየመዋኛ ገንዳ ትልቅ ሳይዝ ...</td>\n",
       "      <td>2020-11-10 06:59:31+00:00</td>\n",
       "      <td>photos\\@sinayelj_182.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4622</th>\n",
       "      <td>SINA KIDS/ሲና ኪድስⓇ</td>\n",
       "      <td>@sinayelj</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-24 10:50:43+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4623 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Channel Title Channel Username     ID  \\\n",
       "0     SINA KIDS/ሲና ኪድስⓇ        @sinayelj  14841   \n",
       "1     SINA KIDS/ሲና ኪድስⓇ        @sinayelj  14840   \n",
       "2     SINA KIDS/ሲና ኪድስⓇ        @sinayelj  14839   \n",
       "3     SINA KIDS/ሲና ኪድስⓇ        @sinayelj  14838   \n",
       "4     SINA KIDS/ሲና ኪድስⓇ        @sinayelj  14837   \n",
       "...                 ...              ...    ...   \n",
       "4618  SINA KIDS/ሲና ኪድስⓇ        @sinayelj    599   \n",
       "4619  SINA KIDS/ሲና ኪድስⓇ        @sinayelj    598   \n",
       "4620  SINA KIDS/ሲና ኪድስⓇ        @sinayelj    197   \n",
       "4621  SINA KIDS/ሲና ኪድስⓇ        @sinayelj    182   \n",
       "4622  SINA KIDS/ሲና ኪድስⓇ        @sinayelj      1   \n",
       "\n",
       "                                                Message  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2     ለኮንዶሚኒየም ለጠባብ ቤቶች ገላግሌ የሆነ ከንፁህ የሲልከን ጥሬ እቃ የተ...   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "4618                                                NaN   \n",
       "4619                 Baby potty\\n0905707448\\n0945097042   \n",
       "4620                                                NaN   \n",
       "4621  ውድ የሲና ኪድስ ደምበኞች በድጋሚ ገብቷል \\nየመዋኛ ገንዳ ትልቅ ሳይዝ ...   \n",
       "4622                                                NaN   \n",
       "\n",
       "                           Date                  Media Path  \n",
       "0     2024-09-26 12:24:51+00:00  photos\\@sinayelj_14841.jpg  \n",
       "1     2024-09-26 12:24:51+00:00  photos\\@sinayelj_14840.jpg  \n",
       "2     2024-09-26 12:24:51+00:00  photos\\@sinayelj_14839.jpg  \n",
       "3     2024-09-26 12:24:12+00:00  photos\\@sinayelj_14838.jpg  \n",
       "4     2024-09-26 12:24:12+00:00  photos\\@sinayelj_14837.jpg  \n",
       "...                         ...                         ...  \n",
       "4618  2021-04-16 18:12:10+00:00    photos\\@sinayelj_599.jpg  \n",
       "4619  2021-04-16 18:12:10+00:00    photos\\@sinayelj_598.jpg  \n",
       "4620  2020-11-26 18:30:52+00:00                         NaN  \n",
       "4621  2020-11-10 06:59:31+00:00    photos\\@sinayelj_182.jpg  \n",
       "4622  2020-07-24 10:50:43+00:00                         NaN  \n",
       "\n",
       "[4623 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(rpath, 'data', 'clean_data.csv')\n",
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nolaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  # Download necessary resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlang\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ALPHA\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.char_classes import ALPHA\n",
    "from spacy.util import compile_infix_regex\n",
    "import pandas as pd\n",
    "\n",
    "# Load a base model (e.g., English) to use for custom tokenization\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "# Customize the tokenizer\n",
    "infixes = (ALPHA,)  # Use alpha characters only (basic Amharic chars)\n",
    "infix_re = compile_infix_regex(infixes)\n",
    "nlp.tokenizer = Tokenizer(nlp.vocab, infix_finditer=infix_re.finditer)\n",
    "\n",
    "\n",
    "# Tokenize each message using spaCy\n",
    "df['tokenized'] = df['Message'].apply(lambda x: [token.text for token in nlp(x)])\n",
    "\n",
    "print(df[['Message', 'tokenized']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def label_message_utf8_with_birr(message):\n",
    "    # Split the message at the first occurrence of '\\n'\n",
    "    if '\\n' in message:\n",
    "        first_line, remaining_message = message.split('\\n', 1)\n",
    "    else:\n",
    "        first_line, remaining_message = message, \"\"\n",
    "    \n",
    "    labeled_tokens = []\n",
    "    \n",
    "    # Tokenize the first line\n",
    "    first_line_tokens = re.findall(r'\\S+', first_line)\n",
    "    \n",
    "    # Label the first token as B-PRODUCT and the rest as I-PRODUCT\n",
    "    if first_line_tokens:\n",
    "        labeled_tokens.append(f\"{first_line_tokens[0]} B-PRODUCT\")  # First token as B-PRODUCT\n",
    "        for token in first_line_tokens[1:]:\n",
    "            labeled_tokens.append(f\"{token} I-PRODUCT\")  # Remaining tokens as I-PRODUCT\n",
    "    \n",
    "    # Process the remaining message normally\n",
    "    if remaining_message:\n",
    "        lines = remaining_message.split('\\n')\n",
    "        for line in lines:\n",
    "            tokens = re.findall(r'\\S+', line)  # Tokenize each line while considering non-ASCII characters\n",
    "            \n",
    "            for token in tokens:\n",
    "                # Check if token is a phone number (e.g., 10 consecutive digits)\n",
    "                if re.match(r'^\\d{10}$', token):\n",
    "                    labeled_tokens.append(f\"{token} I-PHONE\")  # Label as I-PHONE\n",
    "                \n",
    "                # Check if token is a price (e.g., 500 ETB, $100, or ብር)\n",
    "                elif re.match(r'^\\d+(\\.\\d{1,2})?$', token) or 'ETB' in token or 'ዋጋ' in token or '$' in token or 'ብር' in token or 'birr' in token:\n",
    "                    labeled_tokens.append(f\"{token} I-PRICE\")\n",
    "                \n",
    "                # Check if token could be a location (e.g., cities or general location names)\n",
    "                elif any(loc in token for loc in ['Addis Ababa', 'ለቡ', 'ለቡ መዳህኒዓለም', 'መገናኛ', 'ቦሌ', 'ሜክሲኮ', 'ብስራተ', 'ገብርኤል', 'ገርጂ', 'ኢምፔሪያል', 'ህንፃ', 'ፕላዛ', '4ኪሎ', 'ፎቅ', 'ላፍቶ', 'ሞል', 'ስላሴ']):\n",
    "                    labeled_tokens.append(f\"{token} I-LOC\")\n",
    "                \n",
    "                # Assume other tokens are part of a product name or general text\n",
    "                else:\n",
    "                    labeled_tokens.append(f\"{token} O\")\n",
    "    \n",
    "    return \"\\n\".join(labeled_tokens)\n",
    "\n",
    "# Apply the updated function to the non-null messages\n",
    "df['Labeled_Message'] = df['Message'].apply(label_message_utf8_with_birr)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated labeled dataset to a file in CoNLL format\n",
    "labeled_data_birr_path = os.path.join(rpath, 'data', 'labeled_telegram_product_price_location.txt')\n",
    "with open(labeled_data_birr_path, 'w', encoding='utf-8') as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write(f\"{row['Labeled_Message']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data path\n",
    "data_path = os.path.join(rpath, 'data', 'labeled_telegram_product_price_location.txt')\n",
    "\n",
    "# Try specifying the encoding\n",
    "with open(data_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Process lines as needed, assuming you are using tab as the delimiter\n",
    "data = [line.strip().split('\\t') for line in lines]  # Adjust the split based on your delimiter\n",
    "\n",
    "# Create a DataFrame, assuming the first column is 'Labeled_Message' and second for labels\n",
    "labeled_data = pd.DataFrame(data, columns=['Labeled_Message'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(labeled_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for tokens and labels\n",
    "tokens = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over the DataFrame to split the 'Labeled_Message' column\n",
    "for message in labeled_data['Labeled_Message']:\n",
    "    parts = message.split()  # Split the string by whitespace\n",
    "    if len(parts) == 2:      # Ensure that line has exactly two parts\n",
    "        token = parts[0]      # The token (first part)\n",
    "        label = parts[1]      # The label (second part)\n",
    "        tokens.append(token)\n",
    "        labels.append(label)\n",
    "\n",
    "# Create a new DataFrame with the separated tokens and labels\n",
    "df_labeled = pd.DataFrame({\n",
    "    'Token': tokens,\n",
    "    'Label': labels\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_labeled.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
